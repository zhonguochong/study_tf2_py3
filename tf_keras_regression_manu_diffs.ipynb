{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.3\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.21.0\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd,  sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3870, 8) (3870,)\n",
      "(11610, 8) (11610,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state =7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state =11)\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric 使用\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))\n",
    "print(metric([1.], [2.]))\n",
    "print(metric.result())\n",
    "\n",
    "metric.reset_states()\n",
    "metric([1.], [3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0 train_mse:  1.8239747\t valid_mse:  2.2994666\n",
      "Epoch 1 train_mse:  3.14710281 train_mse:  1.5223792\t valid_mse:  2.0310862\n",
      "Epoch 2 train_mse:  5.0915694\t valid_mse:  1.7280037\n",
      "Epoch 3 train_mse:  1.4735624\t valid_mse:  1.4075376\n",
      "Epoch 4 train_mse:  1.267382\t valid_mse:  1.3952736\n",
      "Epoch 5 train_mse:  1.2417814\t valid_mse:  1.3898062\n",
      "Epoch 6 train_mse:  1.2771201\t valid_mse:  1.39172\n",
      "Epoch 7 train_mse:  1.2508684\t valid_mse:  1.3902473\n",
      "Epoch 8 train_mse:  1.2418983\t valid_mse:  1.3904111\n",
      "Epoch 9 train_mse:  1.2578303\t valid_mse:  1.3868707\n",
      "Epoch 10 train_mse:  1.250557\t valid_mse:  1.3888435\n",
      "Epoch 11 train_mse:  1.2542729\t valid_mse:  1.3886325\n",
      "Epoch 12 train_mse:  1.2667555\t valid_mse:  1.3865391\n",
      "Epoch 13 train_mse:  1.2568487\t valid_mse:  1.38592342551289\n",
      "Epoch 14 train_mse:  1.2702876\t valid_mse:  1.3884666\n",
      "Epoch 15 train_mse:  1.2405261\t valid_mse:  1.3895425\n",
      "Epoch 16 train_mse:  1.2473992\t valid_mse:  1.3881953\n",
      "Epoch 17 train_mse:  1.239969\t valid_mse:  1.3881862\n",
      "Epoch 18 train_mse:  1.2573425\t valid_mse:  1.38756877train_mse:  1.2421379\n",
      "Epoch 19 train_mse:  1.2588582\t valid_mse:  1.3888607\n",
      "Epoch 20 train_mse:  1.2613194\t valid_mse:  1.38527train_mse:  1.2647526\n",
      "Epoch 21 train_mse:  1.2498302\t valid_mse:  1.3856779\n",
      "Epoch 22 train_mse:  1.2767096\t valid_mse:  1.3853542\n",
      "Epoch 23 train_mse:  1.2501737\t valid_mse:  1.38562562545347\n",
      "Epoch 24 train_mse:  1.241318\t valid_mse:  1.3939995\n",
      "Epoch 25 train_mse:  1.2743455\t valid_mse:  1.38494832691932\n",
      "Epoch 26 train_mse:  1.2531842\t valid_mse:  1.3838387\n",
      "Epoch 27 train_mse:  1.2663399\t valid_mse:  1.3886385\n",
      "Epoch 28 train_mse:  1.2595319 1.248175\t valid_mse:  1.3873508\n",
      "Epoch 29 train_mse:  1.2500378\t valid_mse:  1.3841845\n",
      "Epoch 30 train_mse:  1.2421381\t valid_mse:  1.3840129\n",
      "Epoch 31 train_mse:  1.249844951.2482297\t valid_mse:  1.3868071\n",
      "Epoch 32 train_mse:  1.22951366train_mse:  1.2256079\t valid_mse:  1.3848671\n",
      "Epoch 33 train_mse:  1.2243019\t valid_mse:  1.39416169\n",
      "Epoch 34 train_mse:  1.2360836\t valid_mse:  1.3838513\n",
      "Epoch 35 train_mse:  1.274579\t valid_mse:  1.386007512\n",
      "Epoch 36 train_mse:  1.2725315\t valid_mse:  1.3832483\n",
      "Epoch 37 train_mse:  1.2695619\t valid_mse:  1.3872006\n",
      "Epoch 38 train_mse:  1.21581896\t valid_mse:  1.3880302\n",
      "Epoch 39 train_mse:  1.246094\t valid_mse:  1.3847253\n",
      "Epoch 40 train_mse:  1.2884638\t valid_mse:  1.38905618\n",
      "Epoch 41 train_mse:  1.2538911\t valid_mse:  1.3841276\n",
      "Epoch 42 train_mse:  1.2604501\t valid_mse:  1.3857753\n",
      "Epoch 43 train_mse:  1.2431387\t valid_mse:  1.385681\n",
      "Epoch 44 train_mse:  1.2433417\t valid_mse:  1.396396\n",
      "Epoch 45 train_mse:  1.2682117\t valid_mse:  1.3850424\n",
      "Epoch 46 train_mse:  1.21968\t valid_mse:  1.3853798\n",
      "Epoch 47 train_mse:  1.2791462\t valid_mse:  1.3836226\n",
      "Epoch 48 train_mse:  1.2397903\t valid_mse:  1.38466\n",
      "Epoch 49 train_mse:  1.237744449 train_mse:  1.261650749 train_mse:  1.2367544\t valid_mse:  1.3841724\n",
      "Epoch 50 train_mse:  1.2527217\t valid_mse:  1.3892068\n",
      "Epoch 51 train_mse:  1.2491906\t valid_mse:  1.3885543\n",
      "Epoch 52 train_mse:  1.2661543\t valid_mse:  1.3838404\n",
      "Epoch 53 train_mse:  1.2618576\t valid_mse:  1.3866401\n",
      "Epoch 54 train_mse:  1.2576966\t valid_mse:  1.3863407\n",
      "Epoch 55 train_mse:  1.2584261\t valid_mse:  1.3862313\n",
      "Epoch 56 train_mse:  1.2576493\t valid_mse:  1.3833346\n",
      "Epoch 57 train_mse:  1.26728424\t valid_mse:  1.3846378\n",
      "Epoch 58 train_mse:  1.26510321.2583882\t valid_mse:  1.3890437\n",
      "Epoch 59 train_mse:  1.2555348\t valid_mse:  1.3834243\n",
      "Epoch 60 train_mse:  1.2557836\t valid_mse:  1.3848325\n",
      "Epoch 61 train_mse:  1.30011\t valid_mse:  1.3849387\n",
      "Epoch 62 train_mse:  1.2728297\t valid_mse:  1.3833053\n",
      "Epoch 63 train_mse:  1.2822946\t valid_mse:  1.3864746rain_mse:  1.3001854\n",
      "Epoch 64 train_mse:  1.2384113\t valid_mse:  1.3882649\n",
      "Epoch 65 train_mse:  1.245246\t valid_mse:  1.3863056\n",
      "Epoch 66 train_mse:  1.2342174\t valid_mse:  1.390576\n",
      "Epoch 67 train_mse:  1.2172985\t valid_mse:  1.3846337\n",
      "Epoch 68 train_mse:  1.27098931.265206968 train_mse:  1.2763683\t valid_mse:  1.3861378\n",
      "Epoch 69 train_mse:  1.2765858\t valid_mse:  1.384325\n",
      "Epoch 70 train_mse:  1.256933\t valid_mse:  1.383650761.2575151\n",
      "Epoch 71 train_mse:  1.266239\t valid_mse:  1.3849683\n",
      "Epoch 72 train_mse:  1.2495347\t valid_mse:  1.3901435\n",
      "Epoch 73 train_mse:  1.2502574\t valid_mse:  1.3832879\n",
      "Epoch 74 train_mse:  1.2694993\t valid_mse:  1.3830708\n",
      "Epoch 75 train_mse:  1.2809608\t valid_mse:  1.3843076\n",
      "Epoch 76 train_mse:  1.2605684\t valid_mse:  1.3866253\n",
      "Epoch 77 train_mse:  1.2649667\t valid_mse:  1.3856947\n",
      "Epoch 78 train_mse:  1.23217\t valid_mse:  1.3856858\n",
      "Epoch 79 train_mse:  1.2804068\t valid_mse:  1.3845757\n",
      "Epoch 80 train_mse:  1.2551697\t valid_mse:  1.3867468\n",
      "Epoch 81 train_mse:  1.2560507\t valid_mse:  1.3924685\n",
      "Epoch 82 train_mse:  1.2543365\t valid_mse:  1.393499\n",
      "Epoch 83 train_mse:  1.284004\t valid_mse:  1.3874516\n",
      "Epoch 84 train_mse:  1.2380979\t valid_mse:  1.3840891\n",
      "Epoch 85 train_mse:  1.2486737\t valid_mse:  1.3847047\n",
      "Epoch 86 train_mse:  1.2466077\t valid_mse:  1.3853811\n",
      "Epoch 87 train_mse:  1.2513043train_mse:  1.2722462train_mse:  1.2819564\t valid_mse:  1.3843014\n",
      "Epoch 88 train_mse:  1.25977891.2648314\t valid_mse:  1.3832273\n",
      "Epoch 89 train_mse:  1.2815094\t valid_mse:  1.3828553\n",
      "Epoch 90 train_mse:  1.2322323\t valid_mse:  1.3869582\n",
      "Epoch 91 train_mse:  1.2618792\t valid_mse:  1.3833761\n",
      "Epoch 92 train_mse:  1.2633753\t valid_mse:  1.3834004\n",
      "Epoch 93 train_mse:  1.265465\t valid_mse:  1.3840673\n",
      "Epoch 94 train_mse:  1.2220343\t valid_mse:  1.3851095\n",
      "Epoch 95 train_mse:  1.2619513\t valid_mse:  1.3867897\n",
      "Epoch 96 train_mse:  1.2175115\t valid_mse:  1.3833219\n",
      "Epoch 97 train_mse:  1.2663236\t valid_mse:  1.3838339\n",
      "Epoch 98 train_mse:  1.2466832\t valid_mse:  1.3839182\n",
      "Epoch 99 train_mse:  1.2704948\t valid_mse:  1.38406788\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#      1.1 自动求导\n",
    "# 2. epoch结束 验证集 metric\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x, y, batch_size = 32):\n",
    "    idx = np.random.randint(0, len(x), size = batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu',\n",
    "                       input_shape = x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch, y_pred))\n",
    "            metric(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print('\\rEpoch', epoch, 'train_mse: ',  metric.result().numpy(), end = '')\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid, y_valid_pred))\n",
    "    print('\\t', 'valid_mse: ', valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_4/kernel:0' shape=(8, 30) dtype=float32, numpy=\n",
       " array([[-3.00352693e-01, -4.87425923e-02,  6.64812746e-03,\n",
       "          8.87374505e-02, -2.78891355e-01,  7.11354660e-03,\n",
       "          8.11677203e-02,  4.55152104e-03,  2.34965593e-01,\n",
       "          2.70316780e-01,  3.92019795e-03,  2.44341940e-02,\n",
       "          4.65687327e-02, -1.27483591e-01, -1.51236534e-01,\n",
       "          5.93427457e-02,  2.22092569e-02,  2.24588085e-02,\n",
       "         -2.11796209e-01,  7.08153099e-02,  1.19280450e-01,\n",
       "         -8.60700756e-02, -1.88025445e-01,  1.97396412e-01,\n",
       "          3.59093606e-01,  2.05393568e-01,  3.63285281e-02,\n",
       "         -2.80048370e-01, -5.55911846e-03,  1.52606249e-01],\n",
       "        [-1.18966311e-01, -4.08890918e-02,  5.68286479e-02,\n",
       "         -9.79080796e-02, -1.78452045e-01, -1.17971689e-01,\n",
       "          1.88890714e-02, -1.51860074e-03, -2.44096175e-01,\n",
       "          2.60230213e-01, -1.06924577e-02,  1.28615886e-01,\n",
       "         -4.09584790e-02, -5.67833474e-03,  3.09483379e-01,\n",
       "          1.80083755e-02, -3.71539630e-02, -1.54573228e-02,\n",
       "         -2.96608228e-02, -4.11075912e-02, -5.79467826e-02,\n",
       "          1.03911832e-01,  1.87150985e-01, -1.01497173e-01,\n",
       "          2.47790828e-01, -9.76143256e-02, -8.37345570e-02,\n",
       "          7.46108666e-02,  8.34611431e-02, -4.01610956e-02],\n",
       "        [-2.49185011e-01,  4.67115492e-02, -1.79777950e-01,\n",
       "          1.92762285e-01, -1.87779710e-01, -3.70298475e-02,\n",
       "         -1.82202086e-01, -1.68308578e-02, -5.04756086e-02,\n",
       "         -5.28479554e-02,  5.80683351e-02, -1.80816427e-02,\n",
       "         -3.15365374e-01,  9.56204757e-02,  1.82099253e-01,\n",
       "         -2.49455944e-01,  1.75475515e-02,  1.28571808e-01,\n",
       "         -1.99605171e-02, -1.27671361e-01,  6.00391882e-04,\n",
       "         -1.57291500e-03,  7.54968747e-02,  6.13859668e-02,\n",
       "          1.26692459e-01, -3.86078991e-02, -9.26474780e-02,\n",
       "          2.86830097e-01, -2.02926084e-01,  7.58127347e-02],\n",
       "        [-2.43286729e-01, -1.76390097e-01,  7.57464394e-02,\n",
       "         -1.52897090e-02,  1.22982480e-01, -6.73288107e-01,\n",
       "          3.76313403e-02, -1.06761098e-01, -1.26748994e-01,\n",
       "         -2.44920015e-01, -9.73526910e-02, -1.67804733e-01,\n",
       "         -4.83098984e-01, -1.24202900e-01,  2.19106361e-01,\n",
       "          7.18682185e-02,  1.61600515e-01, -2.43552014e-01,\n",
       "         -2.28005141e-01, -3.44862193e-01,  1.54407531e-01,\n",
       "         -4.75932434e-02,  2.63181657e-01,  2.37014368e-01,\n",
       "         -1.39196857e-03, -1.92659259e-01, -4.15542811e-01,\n",
       "         -1.13468282e-01,  1.16381422e-01,  1.93432141e-02],\n",
       "        [-8.66064429e-03, -2.18015224e-01, -5.93525693e-02,\n",
       "         -2.66158246e-02,  1.15616553e-01, -7.16554880e-01,\n",
       "          1.77975390e-02, -7.67242983e-02,  1.95418328e-01,\n",
       "          2.74156988e-01, -7.46054351e-02,  3.19810957e-02,\n",
       "         -1.88235426e+00, -1.38870448e-01, -1.27253860e-01,\n",
       "         -4.11675945e-02, -5.59962541e-02,  2.11024331e-03,\n",
       "         -1.31093666e-01,  5.80354454e-03,  2.01612338e-01,\n",
       "          4.14347686e-02, -3.15314651e-01, -8.09402689e-02,\n",
       "         -1.81731004e-02, -7.55004287e-02, -5.46730042e-01,\n",
       "          2.37785786e-01, -6.87812716e-02,  7.32156485e-02],\n",
       "        [-1.64492741e-01, -2.98617870e-01, -1.25185561e+00,\n",
       "         -3.86745453e-01, -6.43431842e-02, -3.27744293e+01,\n",
       "         -2.02348638e+00, -3.57904220e+00, -1.43640935e-01,\n",
       "         -1.35137960e-01, -6.51821017e-01, -1.85765278e+00,\n",
       "         -8.06908011e-01, -4.71450567e-01, -6.16494156e-02,\n",
       "         -4.99887317e-01,  1.63092911e-02, -7.97316968e-01,\n",
       "         -1.16727054e-01, -5.83738148e-01, -2.89715052e-01,\n",
       "         -2.71170378e-01, -4.24374752e-02, -1.96518227e-01,\n",
       "         -4.02410656e-01, -4.09441069e-02, -2.53621216e+01,\n",
       "         -4.43378627e-01, -1.94315061e-01, -3.70503634e-01],\n",
       "        [ 2.69154549e-01, -5.55921756e-02,  1.31869838e-01,\n",
       "          1.81188092e-01, -2.92889085e-02, -8.88718963e-01,\n",
       "         -2.48778954e-01, -3.37329917e-02,  6.77047521e-02,\n",
       "          3.60368252e-01, -1.95501417e-01, -3.18086073e-02,\n",
       "         -2.27489211e-02, -1.76036209e-01, -2.02114448e-01,\n",
       "          4.91091013e-02, -2.79733449e-01,  3.50645706e-02,\n",
       "         -7.87936449e-02, -3.90325934e-01,  6.95700273e-02,\n",
       "          5.88651001e-02, -9.05666947e-02, -1.15328230e-01,\n",
       "         -2.51880055e-03, -1.96320772e-01, -7.10923433e-01,\n",
       "         -2.37061918e-01,  1.24313228e-01,  3.21343392e-01],\n",
       "        [ 3.33321653e-02,  3.72612268e-01,  1.96803614e-01,\n",
       "          4.67833467e-02, -8.43254700e-02, -5.74748442e-02,\n",
       "         -2.11986542e-01,  5.21645173e-02, -3.15843791e-01,\n",
       "         -3.48006934e-01, -1.55627474e-01,  9.82703194e-02,\n",
       "         -7.80483782e-02, -1.09979607e-01,  1.34979501e-01,\n",
       "          5.89875989e-02, -2.20637351e-01, -2.67808558e-03,\n",
       "          8.64381641e-02, -2.76782602e-01, -7.84762800e-02,\n",
       "          2.39407972e-01, -3.43587846e-01,  1.77315269e-02,\n",
       "         -6.14583716e-02, -2.18261957e-01, -7.46969581e-02,\n",
       "          1.54049084e-01,  2.00539902e-01,  6.80790395e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(30,) dtype=float32, numpy=\n",
       " array([-0.01059181, -1.8575022 , -0.29652265, -0.0446857 , -0.1161451 ,\n",
       "        -2.7763617 , -0.7382781 , -0.3454852 ,  0.02415823,  0.06727408,\n",
       "        -0.25719067, -0.74595183, -3.463344  , -0.218535  , -0.16046074,\n",
       "        -0.29974464,  0.20206411, -0.35129926, -0.25106728, -0.6471423 ,\n",
       "        -0.07317434,  0.42175847,  0.00410913, -0.07313512,  0.1709504 ,\n",
       "        -0.28611362, -2.1123405 , -0.15443529, -0.23831733, -0.1473118 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_5/kernel:0' shape=(30, 1) dtype=float32, numpy=\n",
       " array([[ 3.9265350e-02],\n",
       "        [-7.4663706e+00],\n",
       "        [-5.8068520e-01],\n",
       "        [ 1.5763409e-01],\n",
       "        [-2.3518953e-02],\n",
       "        [-4.1262081e-01],\n",
       "        [-2.7377720e+00],\n",
       "        [ 6.6128409e-01],\n",
       "        [ 1.0130490e-01],\n",
       "        [ 1.4134576e-02],\n",
       "        [ 4.6507248e-01],\n",
       "        [-2.8261263e+00],\n",
       "        [ 1.0664044e+01],\n",
       "        [ 4.2034605e-01],\n",
       "        [-9.5621288e-02],\n",
       "        [ 4.9961442e-01],\n",
       "        [ 2.3884735e-01],\n",
       "        [-1.4867593e+00],\n",
       "        [-1.6815688e-01],\n",
       "        [-1.5448668e+00],\n",
       "        [-3.8747944e-02],\n",
       "        [ 2.2466746e-01],\n",
       "        [ 1.4275451e-03],\n",
       "        [-4.8314244e-02],\n",
       "        [ 7.2525233e-02],\n",
       "        [-1.0217382e-01],\n",
       "        [ 4.4545773e-01],\n",
       "        [-2.6651919e-02],\n",
       "        [ 3.6971274e-01],\n",
       "        [-1.3066544e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32, numpy=array([1.8756887], dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train_scaled, y_train,\n",
    "                    epochs = 100,\n",
    "                    validation_data = [x_valid_scaled, y_valid],\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
